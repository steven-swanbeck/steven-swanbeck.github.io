<!DOCTYPE html>
<!-- <body style="background-color:rgb(0, 0, 0);">
    <h1>HTML Articles</h1>
</body> -->
<html>

<head>
    <title>Steven Swanbeck</title>
    <meta charset="UTF-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>
    <meta name="description" content="Steven Swanbeck"/>
    <meta name="keywords" content="steven swanbeck, robotics, ut austin, nuclear and applied robotics group"/>
    <meta name="google-site-verification" content="_84jKoQeQmdGWScBpFXvMaCmgxhsOYs4yGrtqFKsEz0" />

    <link href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:wght@200;300;400;600;700;900&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="assets/css/style.css" />
    <link rel="icon" type="image/x-icon" href="assets/images/ut_shield.png">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-LDSQMLZ3GJ"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-LDSQMLZ3GJ');
    </script> -->
    <title> Steven Swanbeck </title>
</head>

<body>
    <div style="width:1000px;margin: 0px auto;">
        <header id="header" width="400px" style="display:flex;justify-content: space-around;">
            <a href="#profile-intro">Home</a>
            <a href="#updates">Updates</a>
            <a href="#projects">Projects</a>
        </header>
        <div id="profile">
            <div id="profile-pic">
                <img src="assets/images/profile.jpg" />
            </div>
            <div id="profile-intro">
                <div id="profile-name">Steven Swanbeck</div>
                <div id="profile-email">steven dot swanbeck at gmail dot com</div>
                <p align="justify">
                    I am pursuing my MS in Mechanical Engineering and Robotics at The University of Texas at Austin advised by
                    <a href="https://www.me.utexas.edu/people/faculty-directory/pryor">Dr. Mitch Pryor</a> in the <a href="https://robotics.me.utexas.edu/">Nuclear and Applied Robotics Group (NRG)</a>.
                    I am passionate about developing robotic systems that assist humans to solve our greatest challenges. I am broadly interested in perception, manipulation, and human-robot interaction.
                </p>
                <p align="justify">
                    Previously, I finished my BS in Mechanical Engineering from University of Nevada, Reno, advised by <a href="https://www.unr.edu/me/about/people/jun-zhang">Dr. Jun Zhang</a>
                    in the <a href="https://packpages.unr.edu/jun">Smart Robotics Lab</a>.
                </p>
                <p align="justify">
                    I also enjoy playing basketball, rock climbing, origami, puzzles, and sci-fi novels.
                </p>
            
                <div>
                    <!-- <a href="assets/files/Resume.pdf">
                      Resume
                    </a>
                    / -->
                    <a href="https://www.linkedin.com/in/stevenswanbeck">
                      LinkedIn
                    </a>
                    /
                    <a href="https://github.com/steven-swanbeck">
                      Github
                    </a>
                    </a>
                </div>
            </div>
            <div style="clear: both;"></div>
        </div>
        <div class="section" id="updates">
            <h1>Updates</h1>
            <ul>
                <li> <b>Aug 2022</b> I'm joining the <a href="https://robotics.me.utexas.edu/">Nuclear and Applied Robotics Group</a> advised by Dr. Mitch Pryor!</li>
                <li> <b>Aug 2022</b> I'm starting my MS in robotics at UT Austin.
                <!-- <li> <b>Apr 2022</b> My first <a href="https://ieeexplore.ieee.org/abstract/document/9969176"> paper</a> is accepted to IEEE Transactions on Robotics</li> -->
                <li> <b>Dec 2021</b> I graduated Summa Cum Laude as the valedictorian of the engineering class with my BS from UNR.</li>
                <li> <b>Aug 2021</b> I'm starting research with the <a href="https://packpages.unr.edu/jun">Smart Robotics Lab</a> advised by Dr. Jun Zhang!</li>
                <li> <b>May 2021</b> I started learning how to build mechatronic systems with Arduino and how to code with C, C++, and Python.</li>
                <li> <b>May 2021</b> I completed my first robotics class, Dr. Jun Zhang's ME422 Introduction to Robotics, and pivoted my aspirations from aerospace engineering toward robotics.</li>
            </ul>
            <p></p>
            <div style="clear: both;"></div>
        </div>
        <div class="divider"></div>
        <div style="display:flex;flex-direction: column;" id="projects">
            <h1>Projects</h1>
            
            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/ar_star.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    Using Augmented Reality to Assess and Modify Mobile Manipulator Surface Repair Plans
                </a>
                <p>
                    <a style="color:#000;" href="https://www.linkedin.com/in/frankregal/">Frank Regal,</a>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="">Fabian Parra,</a>
                    <a style="color:#000;" href="">Jared Rosenbaum,</a>
                    <a style="color:#000;" href="https://www.me.utexas.edu/people/faculty-directory/pryor">Mitch Pryor</a>
                    <br> XR-ROB Second International Workshop on "Horizons of Extended Robotics Reality" @ IEEE IROS (2023) <br>
                    <b>Jul 2023 - Present</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="">Paper (coming soon)</a>
                    <li>Using an AR head-mounted display, a user is able to view predictions made by a surveying robot for surface repair.</li>
                    <li>The user can accept, reject, or modify the plan generated by the robot to prevent incidental covering of sensitive material or repair of unproblematic surfaces.</li>
                </p>
            </div>
            
            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/stch_demo.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    Non-Contact Surface Coverage of Corroded Material
                </a>
                <p>
                    <b>Steven Swanbeck</b>,
                    <br> Ongoing Research Project <br>
                    <b>May 2023 - Present</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="">Code (coming soon)</a>
                    <li>Surface identification used to extract the locations and geometries of possible corroded surfaces within industrial environments.</li>
                    <li>Coverage planning and execution over the identified surfaces using a mobile manipulator system with a protective spray coating prevents further corrosion development.</li>
                </p>
            </div>
            
            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/virtual_fixtures.mp4" type="video/mp4">
                        </video>
                    </center>
                    </a>
                <a href="" class="research-proj-title">
                    Virtual Fixture Generation and Execution for Surface Coverage of Complex Geometries
                </a>
                <p>
                    <b>Steven Swanbeck</b>,
                    <br> Ongoing Research Project <br>
                    <b>May 2023 - Present</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="">Code (coming soon)</a>
                    <li>Using computer vision models, LiDAR detection models, or supervised scene labeling, surfaces on which a robot should perform surface inspection are denoted.</li>
                    <li>A discrete pose mesh is created offset from the surface that can be traversed using a manipulator to perform the surface coverage task.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/detection_fusion.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    LiDAR & Image Data Fusion for Object Detection
                </a>
                <p>
                    <b>Steven Swanbeck</b>
                    <br> Ongoing Research Project <br>
                    <b>Jan 2023 - Present</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="">Code (coming soon)</a>
                    <li>Separate trained LiDAR-based and image-based prediction models are used to make semantic (point-wise/pixel-wise) predictions about the presence of objects of interest within the robot environment.</li>
                    <li>Predictions are fused spatially using projection and probabilistically in the Bayesian sense to predict the locations of these objects in the environment.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/mapping.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    Mapping Stack for Industrial Survey Applications
                </a>
                <p>
                    <b>Steven Swanbeck</b>
                    <br> Research Project <br>
                    <b>Nov 2022 - Mar 2023</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="">Code (coming soon)</a>
                    <li>Custom mapping stack developed to create dense 3D representations of robot surroundings using fused 2D image and 3D LiDAR data.</li>
                    <li>Processing functionalities can be easily implemented to localize and ground regions of interest within the environment; map is also used for robot localization as it is developed.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/game_player.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="https://github.com/steven-swanbeck/robot_shell_game" class="research-proj-title">
                    Robotic Street Scam Artist
                </a>
                <p>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="">Jared Rosenbaum</a>
                    <br> Course Project <br>
                    <b>Oct 2022 - Nov 2022</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://github.com/steven-swanbeck/robot_shell_game">Code</a>
                    <li>Combining manipulator control and computer vision, an eye-in-hand system is able to localize and track a series of shells as they are shuffled, inspect each to look for a planted marker, and pick it to reveal the money.</li>
                    <li>Hand-tracking using the manipulator and writing calculation results also developed as intermediate steps.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/modeling.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    Kinematic Modeling of a Twisted-String Actuated Soft Robotic Finger as Part of an Anthropomorphic Gripper
                </a>
                <p>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="https://www.linkedin.com/in/revanthraghuram-konda-56bbb2158/">Revanth Konda,</a>
                    <a style="color:#000;" href="https://www.unr.edu/me/about/people/jun-zhang">Jun Zhang</a>
                    <br> Modeling, Estimation, and Control Conference (MECC 2023) <br>
                    <b>Apr 2022 - Aug 2022</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="">Paper (coming soon)</a>
                    <li>Modeling strategies for a twisted-string actuator-driven soft robotic gripper developed to enable control and autonomous capabilities.</li>
                </p>
            </div>

            <div>
                <a href="https://ieeexplore.ieee.org/abstract/document/10196149" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/star2.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="https://ieeexplore.ieee.org/abstract/document/10196149" class="research-proj-title">
                    STARâ€“2: A Soft Twisted-string-actuated Anthropomorphic Robotic Gripper: Design, Fabrication, and Preliminary Testing
                </a>
                <p>
                    <a style="color:#000;" href="https://www.linkedin.com/in/aaron-baker-310baa206/">Aaron Baker,</a>
                    <a style="color:#000;" href="">Claire Foy,</a>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="https://www.linkedin.com/in/revanthraghuram-konda-56bbb2158/">Revanth Konda,</a>
                    <a style="color:#000;" href="https://www.unr.edu/me/about/people/jun-zhang">Jun Zhang</a>
                    <br> IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM 2023) <br>
                    <b>Mar 2022 - Aug 2022</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://ieeexplore.ieee.org/abstract/document/10196149">Paper</a>
                    <li>2.0 version of previous soft gripper with increased range-of-motion and degrees-of-freedom.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/gripper_arm.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="https://github.com/steven-swanbeck/ROS_ur3ehand" class="research-proj-title">
                    Dexterous Soft Gripper Manipulator Integration
                </a>
                <p>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="https://www.linkedin.com/in/aaron-baker-310baa206/">Aaron Baker</a>
                    <br> Research Project <br>
                    <b>Feb 2022 - Aug 2022</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://github.com/steven-swanbeck/ROS_ur3ehand">Code</a>
                    <li>Enhanced version of anthropomorphic gripper with 5 additional degrees of freedom integrated with a UR3e manipulator.</li>
                    <li>ROS integration allowed for coordinated control of gripper and manipulator, enabling pick-and-place and human-robot interaction demonstrations.</li>
                </p>
            </div>

            <div>
                <a href="https://ieeexplore.ieee.org/abstract/document/9969176" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/gripper_tro.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="https://ieeexplore.ieee.org/abstract/document/9969176" class="research-proj-title">
                    Anthropomorphic Twisted String-Actuated Soft Robotic Gripper With Tendon-Based Stiffening
                </a>
                <p>
                    <a style="color:#000;" href="https://www.linkedin.com/in/revanthraghuram-konda-56bbb2158/">Revanth Konda*,</a>
                    <a style="color:#000;" href="https://www.linkedin.com/in/david-bombara-jr/">David Bombara*,</a>
                    <b>Steven Swanbeck*</b>,
                    <a style="color:#000;" href="https://www.unr.edu/me/about/people/jun-zhang">Jun Zhang</a>
                    <br> IEEE Transactions on Robotics (April 2023) <br>
                    <b>Sep 2021 - Feb 2022</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://ieeexplore.ieee.org/abstract/document/9969176">Paper</a> 
                    <li>Soft gripper capable of mimicking many of the grasping capabilities of the human hand, including achieving 31/33 grasps of the Feix GRASP Taxonomy and resisting a maximum force of 72N, over 13 times its own weight.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/quadruped2.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    Sublunar Exploration Quadruped
                </a>
                <p>
                    <b>Steven Swanbeck</b>
                    <br> NASA University Student Design Challenge <br>
                    <b>May 2021 - Aug 2021</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://github.com/steven-swanbeck/SublunarExplorationQuadruped.git">Code</a>
                    <li>Project to design a robotic system capable of surveying lava tubes under the surface of the moon to assess their ability to sustain long-term human habitation.</li>
                    <li>Custom quarupedal system capable of teleoperated walking, self-stabilization, and LiDAR mapping of surroundings.</li>
                </p>
            </div>

            <div>
                <p>* indicates equal contribution</p>
            </div>

            <div style="clear: both;"></div>
        </div>
        <div class="divider"></div>
