<!DOCTYPE html>
<!-- <body style="background-color:rgb(0, 0, 0);">
    <h1>HTML Articles</h1>
</body> -->
<html>

<head>
    <title>Steven Swanbeck</title>
    <meta charset="UTF-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>
    <meta name="description" content="The personal website and online portfolio of Steven Swanbeck, a robotics researcher at The University of Texas at Austin."/>
    <meta name="keywords" content="steven swanbeck, robotics, machine learning, artifical intelligence, ut austin, nuclear and applied robotics group"/>
    <meta name="google-site-verification" content="_84jKoQeQmdGWScBpFXvMaCmgxhsOYs4yGrtqFKsEz0" />

    <link href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:wght@200;300;400;600;700;900&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="assets/css/style.css" />
    <link rel="icon" type="image/x-icon" href="assets/images/ut_shield.png">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-LDSQMLZ3GJ"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-LDSQMLZ3GJ');
    </script> -->
    <title> Steven Swanbeck </title>
</head>

<body>
    <div style="width:1000px;margin: 0px auto;">
        <header id="header" width="400px" style="display:flex;justify-content: space-around;">
            <a href="#profile-intro">Home</a>
            <a href="#updates">Updates</a>
            <a href="#projects">Projects</a>
        </header>
        <div id="profile">
            <div id="profile-pic">
                <img src="assets/images/profile.jpg" />
            </div>
            <div id="profile-intro">
                <div id="profile-name">Steven Swanbeck</div>
                <div id="profile-email">steven dot swanbeck at gmail dot com</div>
                <p align="justify">
                    I am pursuing my MS in Mechanical Engineering and Robotics at The University of Texas at Austin advised by
                    <a href="https://www.me.utexas.edu/people/faculty-directory/pryor">Dr. Mitch Pryor</a> in the <a href="https://robotics.me.utexas.edu/">Nuclear and Applied Robotics Group (NRG)</a>.
                    I am passionate about developing robotic systems that assist humans to solve our greatest challenges. I am broadly interested in perception, manipulation, and human-robot interaction.
                </p>
                <p align="justify">
                    Previously, I completed my BS in Mechanical Engineering from the University of Nevada, Reno, advised by <a href="https://www.unr.edu/me/about/people/jun-zhang">Dr. Jun Zhang</a>
                    in the <a href="https://sites.google.com/view/unrsml/home">Smart Robotics Lab</a>.
                </p>
                <p align="justify">
                    Aside from robotics, I also enjoy basketball, rock climbing, origami, puzzles, and sci-fi novels.
                </p>
            
                <div>
                    <!-- <a href="assets/files/Resume.pdf">
                      Resume
                    </a>
                    / -->
                    <a href="https://www.linkedin.com/in/stevenswanbeck">
                      LinkedIn
                    </a>
                    /
                    <a href="https://github.com/steven-swanbeck">
                      Github
                    </a>
                    </a>
                </div>
            </div>
            <div style="clear: both;"></div>
        </div>
        <div class="section" id="updates">
            <h1>Updates</h1>
            <ul>
                <li> <b>Aug 2022</b> I'm joining the <a href="https://robotics.me.utexas.edu/">Nuclear and Applied Robotics Group</a> advised by Dr. Mitch Pryor!</li>
                <li> <b>Aug 2022</b> I'm starting my MS in robotics at UT Austin.
                <!-- <li> <b>Apr 2022</b> My first <a href="https://ieeexplore.ieee.org/abstract/document/9969176"> paper</a> is accepted to IEEE Transactions on Robotics</li> -->
                <li> <b>Dec 2021</b> I graduated Summa Cum Laude as the valedictorian of the engineering class with my BS from UNR.</li>
                <li> <b>Aug 2021</b> I'm starting research with the <a href="https://packpages.unr.edu/jun">Smart Robotics Lab</a> advised by Dr. Jun Zhang!</li>
                <li> <b>May 2021</b> I started learning how to build mechatronic systems with Arduino and how to code with C, C++, and Python.</li>
                <li> <b>May 2021</b> I completed my first robotics class, Dr. Jun Zhang's ME422 Introduction to Robotics, and pivoted my aspirations from aerospace engineering toward robotics.</li>
            </ul>
            <p></p>
            <div style="clear: both;"></div>
        </div>
        <div class="divider"></div>
        <div style="display:flex;flex-direction: column;" id="projects">
            <h1>Projects</h1>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/surface_repair2_thumbnail.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    A SLAM and Object Extraction Pipeline for Informing Contact and Non-Contact Manipulation Tasks
                </a>
                <p>
                    <b>Steven Swanbeck</b>
                    <br> Research Project &nbsp;&nbsp;&nbsp;&nbsp; <br>
                    <b>Jan 2024 - Present</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://github.com/steven-swanbeck/autonomous_robots">Code (coming soon)</a>
                    <li>Supports custom plugins for image-based predictions and supports fusion of image data with depth images and point clouds generated by robot sensors.</li>
                    <li>A grounded Segment Anything plugin is implemented to extract objects using text inputs.</li>
                    <Supports>Using behavior trees, the processes associated with data collection, annotation, fusion, and storage can be easily adjusted to fit a desired task, and the stack supports any number of visual data sensors out of the box (subject to computational constraints).</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/autonomous_robots_summary.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="https://github.com/steven-swanbeck/autonomous_robots" class="research-proj-title">
                    Autonomous Obstacle Avoidance, Localization, Navigation, and SLAM on a Mobile Robot
                </a>
                <p>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="">Daniel Meza,</a>
                    <a style="color:#000;" href="">Jared Rosenbaum</a>
                    <br> Course Project &nbsp;&nbsp;&nbsp;&nbsp; <br>
                    <b>Jan 2024 - Apr 2024</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://github.com/steven-swanbeck/autonomous_robots">Code</a>
                    <li>Simple obstacle avoidance, particle filter-based localization, navigation using RRT* for global planning and a line-of-sight carrot planner for local planning, and SLAM using correlative scan matching and GTSAM for pose graph optimization implemented to run onboard an autonomous mobile robot in real time.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/hylacomylus_example.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    Hylacomylus: Memory Efficient and Robot-Agnostic SLAM for Operation in Large-Scale Environments with Computationally-Limited Hardware 
                </a>
                <p>
                    <b>Steven Swanbeck</b>
                    <br> Research Project &nbsp;&nbsp;&nbsp;&nbsp; <br>
                    <b>Jan 2024 - Apr 2024</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="">Code (coming soon)</a>
                    <li><i>Hylacomylus</i> implements pure visual SLAM using <a href="https://github.com/PRBonn/kiss-icp">KISS-ICP</a> with dynamic data loading and unloading properties to allow comutationally-limited robots to produce and maintain highly-detailed maps of space that remain computationally- and memory-friendly.</li>
                    <li>Produced maps can be effortlessly reloaded into working memory, transferred to other systems for use, or added to.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/gators_square.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    GaTORS: A Game-Theoretic Tool for Optimal Robot Platform Selection and Design in Surface Coverage Applications 
                </a>
                <p>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="">Daniel Meza,</a>
                    <a style="color:#000;" href="">Jared Rosenbaum,</a>
                    <a style="color:#000;" href="">David Fridovich-Keil,</a>
                    <a style="color:#000;" href="">Mitch Pryor</a>
                    <br> Submitted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024) &nbsp;&nbsp;&nbsp;&nbsp; <br>
                    <b>Jan 2024 - Mar 2024</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="">Paper (coming soon)</a>
                    <li>GaTORS presents a framework that helps answer the questions of <i>which</i> and <i>how many</i> robots should be deployed in real world environments to complete surface coverage tasks.</li>
                    <li>The design of systems can also be optimized by performing systematic parameter sweeps over the space of possible configurations to set targets to achieve economic viability.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/ar_star_interactions.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    AR-STAR: An Augmented Reality Tool for Online Modification of Robot Point Cloud Data
                </a>
                <p>
                    <a style="color:#000;" href="">Frank Regal*,</a>
                    <b>Steven Swanbeck*</b>,
                    <a style="color:#000;" href="">Fabian Parra,</a>
                    <a style="color:#000;" href="">Mitch Pryor</a>
                    <br> ACM/IEEE International Conference on Human-Robot Interaction (HRI '24) &nbsp;&nbsp;&nbsp;&nbsp; <br>
                    <b>Oct 2023 - Dec 2023</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://dl.acm.org/doi/10.1145/3610978.3640571">Paper</a>
                    <li>Uncertainty in sensor data collected onboard a deployed robot can hinder its ability to complete a mission, and it can be difficult for a robot to autonomously detect and overcome these uncertainties.</li>
                    <li>We develop an augmented reality tool that allows a a human supervisor to visualize a robot's predictions and modify them online using one of three interaction modalities and study user preferences in using them.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/magneto_rl.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    Reinforcement Learning for Traversal of Uncertain Vertical Terrain using a Magnetic Wall-Climbing Robot 
                </a>
                <p>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="">Jee-Eun Lee</a>
                    <br> Course Project &nbsp;&nbsp;&nbsp;&nbsp; <br>
                    <b>Sep 2023 - Dec 2023</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://github.com/steven-swanbeck/magneto_rl.git">Code</a>
                    <li>Using only its own kinematics, magnetic forces experienced at its feet, and a goal position, a magnetic wall climbing robot is trained to navigate a surface within unknown and irregular magnetic properties.</li>
                    <li>Developed a custom ROS-based bridge to interface the C++ simulation toolkit DART with Python RL libraries and trained Deep Q-Learning and PPO policies using it.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/we_paint.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    Game-Theoretic Modeling for Robot Platform Selection in Industrial Repair Applications 
                </a>
                <p>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="">Daniel Meza,</a>
                    <a style="color:#000;" href="">Jared Rosenbaum</a>
                    <br> Course Project &nbsp;&nbsp;&nbsp;&nbsp; <br>
                    <b>Oct 2023 - Dec 2023</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://github.com/steven-swanbeck/game_theoretic_painting.git">Code</a>
                    <li>Using game-theoretic modeling, the ability of different robotic hardware platforms to perform maintenance and inspection tasks in a shared environment is evaluated.</li>
                    <li>With this competitive modeling approach, the ability to select a minimally-sized heterogeneous robot team to accomplish comprehensive corrosion repairs within predefined budget and time constraints in complex industrial environments was demonstrated.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/ar_star.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="https://arxiv.org/abs/2311.00988" class="research-proj-title">
                    Using Augmented Reality to Assess and Modify Mobile Manipulator Surface Repair Plans
                </a>
                <p>
                    <a style="color:#000;" href="https://www.linkedin.com/in/frankregal/">Frank Regal,</a>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="">Fabian Parra,</a>
                    <a style="color:#000;" href="">Jared Rosenbaum,</a>
                    <a style="color:#000;" href="https://www.me.utexas.edu/people/faculty-directory/pryor">Mitch Pryor</a>
                    <br> XR-ROB Second International Workshop on "Horizons of Extended Robotics Reality" @ IEEE IROS (2023) &nbsp;&nbsp;&bull;&nbsp;&nbsp; <strong>Second Prize</strong> <br>
                    <b>Jul 2023 - Aug 2023</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://arxiv.org/abs/2311.00988">Paper</a>
                    <li>Using an AR head-mounted display, a user is able to view predictions made by a surveying robot for surface repair.</li>
                    <li>The user can accept, reject, or modify the plan generated by the robot to prevent incidental covering of sensitive material or repair of unproblematic surfaces.</li>
                </p>
            </div>
            
            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/corrosion_repair_demo.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    Non-Contact Surface Coverage of Corroded Material in Industrial Environments
                </a>
                <p>
                    <b>Steven Swanbeck</b>
                    <br> Research Project <br>
                    <b>May 2023 - Present</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="">Code (coming soon)</a>
                    <li>Surface identification used to extract the locations and geometries of possible corroded surfaces within industrial environments.</li>
                    <li>Coverage planning and execution with constraint-relaxed redundant replanning enables coverage over the identified surfaces using a mobile manipulator system with a protective spray coating, preventing further corrosion development.</li>
                </p>
            </div>
            
            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/virtual_fixtures.mp4" type="video/mp4">
                        </video>
                    </center>
                    </a>
                <a href="" class="research-proj-title">
                    Virtual Fixture Generation and Execution for Surface Coverage of Complex Geometries
                </a>
                <p>
                    <b>Steven Swanbeck</b>
                    <br> Research Project <br>
                    <b>May 2023 - Jul 2023</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="">Code (coming soon)</a>
                    <li>Using computer vision models, LiDAR detection models, or supervised scene labeling, surfaces on which a robot should perform surface inspection are denoted.</li>
                    <li>A discrete pose mesh is created offset from the surface that can be traversed using a manipulator to perform the surface coverage task.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/passive_drone_gripper_alt.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="https://github.com/steven-swanbeck/passive_tree_gripper/" class="research-proj-title">
                    Bat-Inspired Passive Drone Gripper for Angle-Invariant Perching
                </a>
                <p>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="">Caleb Horan</a>,
                    <a style="color:#000;" href="">Jared Rosenbaum</a>
                    <br> Course Project <br>
                    <b>March 2023 - April 2023</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://github.com/steven-swanbeck/passive_tree_gripper/">Code</a>
                    <li>A custom mechanism inspired by the passive inverted hanging ability of bats to allow a drone to remain perched in one location for long periods of time without expending battery power.</li>
                    <li>In addition to perching in upright or inverted orientations, the gripper can also be used as landing gear for the drone or for holding objects during flight.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/ik_toolbox.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="https://github.com/steven-swanbeck/AlgorithmsforSensorBasedRobotics" class="research-proj-title">
                    A MATLAB Toolbox using Screw Theory for Forward and Inverse Kinematics of Manipulators
                </a>
                <p>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="">Jared Rosenbaum</a>
                    <br> Course Project <br>
                    <b>Feb 2023 - April 2023</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://github.com/steven-swanbeck/AlgorithmsforSensorBasedRobotics">Code</a>
                    <li>Robots of arbitrary structure can be defined and visualized using screw theory.</li>
                    <li>Space frame and body frame forward kinematics can be calculated and visualized and manipulability measures are calculated and monitored.</li>
                    <li>Various inverse kinematics algorithms, including Jacobian pseudo-inverse, Jacobian transpose, redundancy resolution, and damped least-squares are available.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/detection_fusion_and_pipeline.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    LiDAR & Image Data Fusion for Object Detection with Rapid Labeling and Training Pipeline
                </a>
                <p>
                    <b>Steven Swanbeck</b>
                    <br> Research Project <br>
                    <b>Jan 2023 - Jun 2023</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="">Code (coming soon)</a>
                    <li>Separate trained LiDAR-based and image-based prediction models are used to make semantic (point-wise/pixel-wise) predictions about the presence of objects of interest within the robot environment.</li>
                    <li>Predictions are fused spatially using projection and probabilistically in the Bayesian sense to predict the locations of these objects in the environment.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/mapping.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    Visual Inspection and Mapping Stack for Industrial Survey Applications
                </a>
                <p>
                    <b>Steven Swanbeck</b>
                    <br> Research Project <br>
                    <b>Nov 2022 - Mar 2023</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="">Code (coming soon)</a>
                    <li>Custom mapping stack developed to create dense 3D representations of robot surroundings using fused 2D image and 3D LiDAR data.</li>
                    <li>Processing functionalities can be easily implemented to localize and ground regions of interest within the environment; map is also used for robot localization as it is developed.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/game_player.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="https://github.com/steven-swanbeck/robot_shell_game" class="research-proj-title">
                    Robotic Street Scam Artist
                </a>
                <p>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="">Jared Rosenbaum</a>,
                    <a style="color:#000;" href="">Caleb Horan</a>,
                    <a style="color:#000;" href="">Alex Macris</a>
                    <br> Course Project <br>
                    <b>Oct 2022 - Nov 2022</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://github.com/steven-swanbeck/robot_shell_game">Code</a>
                    <li>Combining manipulator control and computer vision, an eye-in-hand system is able to localize and track a series of shells as they are shuffled, inspect each to look for a planted marker, and pick it to reveal the money in a modified version of the classic street scam shell game.</li>
                    <li>Hand-tracking using the manipulator and writing calculation results also developed as intermediate steps.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/modeling.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    Kinematic Modeling of a Twisted-String Actuated Soft Robotic Finger as Part of an Anthropomorphic Gripper
                </a>
                <p>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="https://www.linkedin.com/in/revanthraghuram-konda-56bbb2158/">Revanth Konda,</a>
                    <a style="color:#000;" href="https://www.unr.edu/me/about/people/jun-zhang">Jun Zhang</a>
                    <br> Modeling, Estimation, and Control Conference (MECC 2023) <br>
                    <b>Apr 2022 - Aug 2022</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://www.sciencedirect.com/science/article/pii/S240589632302390X">Paper</a>
                    <li>Modeling strategies for a twisted-string actuator-driven soft robotic gripper developed to enable control and autonomous capabilities.</li>
                </p>
            </div>

            <div>
                <a href="https://ieeexplore.ieee.org/abstract/document/10196149" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/star2.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="https://ieeexplore.ieee.org/abstract/document/10196149" class="research-proj-title">
                    STAR–2: A Soft Twisted-string-actuated Anthropomorphic Robotic Gripper: Design, Fabrication, and Preliminary Testing
                </a>
                <p>
                    <a style="color:#000;" href="https://www.linkedin.com/in/aaron-baker-310baa206/">Aaron Baker,</a>
                    <a style="color:#000;" href="">Claire Foy,</a>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="https://www.linkedin.com/in/revanthraghuram-konda-56bbb2158/">Revanth Konda,</a>
                    <a style="color:#000;" href="https://www.unr.edu/me/about/people/jun-zhang">Jun Zhang</a>
                    <br> IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM 2023) <br>
                    <b>Mar 2022 - Aug 2022</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://ieeexplore.ieee.org/abstract/document/10196149">Paper</a>
                    <li>2.0 version of previous soft gripper with increased range-of-motion and degrees-of-freedom.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/gripper_arm.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="https://github.com/steven-swanbeck/ROS_ur3ehand" class="research-proj-title">
                    Dexterous Soft Gripper Manipulator Integration for Human-Robot Interaction
                </a>
                <p>
                    <b>Steven Swanbeck</b>,
                    <a style="color:#000;" href="https://www.linkedin.com/in/aaron-baker-310baa206/">Aaron Baker</a>
                    <br> Research Project <br>
                    <b>Feb 2022 - Aug 2022</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://github.com/steven-swanbeck/ROS_ur3ehand">Code</a>
                    <li>Enhanced version of anthropomorphic gripper with 5 additional degrees of freedom integrated with a UR3e manipulator.</li>
                    <li>ROS integration allowed for coordinated control of gripper and manipulator, enabling pick-and-place and human-robot interaction demonstrations.</li>
                </p>
            </div>

            <div>
                <a href="https://ieeexplore.ieee.org/abstract/document/9969176" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/gripper_tro.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="https://ieeexplore.ieee.org/abstract/document/9969176" class="research-proj-title">
                    Anthropomorphic Twisted String-Actuated Soft Robotic Gripper With Tendon-Based Stiffening
                </a>
                <p>
                    <a style="color:#000;" href="https://www.linkedin.com/in/revanthraghuram-konda-56bbb2158/">Revanth Konda*,</a>
                    <a style="color:#000;" href="https://www.linkedin.com/in/david-bombara-jr/">David Bombara*,</a>
                    <b>Steven Swanbeck*</b>,
                    <a style="color:#000;" href="https://www.unr.edu/me/about/people/jun-zhang">Jun Zhang</a>
                    <br> IEEE Transactions on Robotics (April 2023) <br>
                    <b>Sep 2021 - Feb 2022</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://ieeexplore.ieee.org/abstract/document/9969176">Paper</a> 
                    <li>Soft gripper capable of mimicking many of the grasping capabilities of the human hand, including achieving 31/33 grasps of the Feix GRASP Taxonomy and resisting a maximum force of 72N, over 13 times its own weight.</li>
                </p>
            </div>

            <div>
                <a href="" style="height: 12em;" class="research-thumb">
                    <center>
                        <video width="320" height="200" playsinline autoplay loop muted>
                            <source src="assets/images/quadruped2.mp4" type="video/mp4">
                        </video>
                    </center>
                </a>
                <a href="" class="research-proj-title">
                    Sublunar Lava Tube Exploration Quadruped
                </a>
                <p>
                    <b>Steven Swanbeck</b>
                    <br> NASA University Student Design Challenge <br>
                    <b>May 2021 - Aug 2021</b>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://github.com/steven-swanbeck/SublunarExplorationQuadruped.git">Code</a>
                    <li>Project to design a robotic system capable of surveying lava tubes under the surface of the moon to assess their ability to sustain long-term human habitation.</li>
                    <li>Custom quarupedal system capable of teleoperated walking, self-stabilization, and LiDAR mapping of surroundings.</li>
                </p>
            </div>

            <div>
                <p>* indicates equal contribution</p>
            </div>

            <div style="clear: both;"></div>
        </div>
        <div class="divider"></div>
